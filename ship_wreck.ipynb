{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sb\nimport matplotlib.pyplot as plt # we only need pyplot\nsb.set() # set the default Seaborn style for graphics\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\ntrain_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n#checking the the type and dimension of the data\nprint(\"Data Type: \",train_data.dtypes)\nprint(\"Data Dims:\", train_data.shape)\n\n# To do Data exploration/Cleaning \n\n\n#Splitting the data for preparation for testing. \nsurvived_train, survived_test, gender_train, gender_test = train_test_split(train_data['Survived'], train_data['Sex'], test_size=0.2, random_state=42)\n\n#check the size of train and test\n\nprint(\"Train set: \", survived_train.shape, gender_train.shape)\nprint(\"Test set: \", gender_test.shape, gender_test.shape)\n\n\n#To do Modelling \n\n\n\n\n\n\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-10T08:49:42.630125Z","iopub.execute_input":"2022-03-10T08:49:42.630414Z","iopub.status.idle":"2022-03-10T08:49:42.650402Z","shell.execute_reply.started":"2022-03-10T08:49:42.630373Z","shell.execute_reply":"2022-03-10T08:49:42.649405Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Data Type:  PassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object\nData Dims: (891, 12)\nTrain set:  (712,) (712,)\nTest set:  (179,) (179,)\n","output_type":"stream"}]}]}